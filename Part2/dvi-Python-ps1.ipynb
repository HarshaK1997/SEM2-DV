{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0BQyBwNnDRi"
   },
   "source": [
    "<img src = \"https://www.bits-pilani.ac.in/Uploads/Campus/BITS_university_logo.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wOCvWHupnDSZ"
   },
   "source": [
    "<h1><center>Work Integrated Learning Programmes Division<br>\n",
    "M.Tech (Data Science and Engineering)<br> Data Visualization And Interpretation<br>\n",
    "</center></h1>\n",
    "\n",
    "<h2><center>Assignment -Python â€“ PS1 [Weightage 13%]</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sp26I5vbnDSm"
   },
   "source": [
    "<ol>\n",
    "  <li>Do not change the name of the data file that is shared with the problem statement.</li>\n",
    "  <li>If intermediate data files are created, retain in the present working directory and attach them during submission.</li>\n",
    "  <li>Retain the data file in the same directory as that of this workbook.</li>\n",
    "  <li>Retain the Visualizations that is produced in the file. Don't clear them away.</li>\n",
    "  <li>Submit only the .IPYNB file. Intermediate files to be attached as mentioned in (2).</li>\n",
    "  <li>All the visuals should adhere to the visualization principles learnt in the Course and must be presentation ready. Most effective visuals would fetch maximum  credits</li>\n",
    "  <li>Submissions done via means other than CANAVAS will strictly be NOT graded.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GuvPynfInDS4"
   },
   "source": [
    "<style>\n",
    "table {\n",
    "  font-family: arial, sans-serif;\n",
    "  border-collapse: collapse;\n",
    "  width: 100%;\n",
    "}\n",
    "\n",
    "td, th {\n",
    "  border: 1px solid #dddddd;\n",
    "  text-align: left;\n",
    "  padding: 8px;\n",
    "}\n",
    "\n",
    "tr:nth-child(even) {\n",
    "  background-color: #dddddd;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<h2>Group No: (mention your group number here)</h2>\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Full Name</th>\n",
    "    <th>BITS ID</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Deepak Kajla</td>\n",
    "    <td>2023cs04003</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Harsha K</td>\n",
    "    <td>2023cs04018</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Sahitya Srinivasan</td>\n",
    "    <td>2023cs04028</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Santhosh Bhat</td>\n",
    "    <td>2023cs04041</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSiG-H2XnDTF"
   },
   "source": [
    "<h3>Objective</h3>\n",
    "<h4>To find best players from each positions with their age, nationality, club based on their Potential Scores</h4>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SpP42_ZgnDTN"
   },
   "source": [
    "##  Download and Prep the Data: 1 Marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVZP7GmMnDTV"
   },
   "source": [
    "<h4>Import the libraries needed</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ru_e-YoynDTc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9k16HmSnDTj"
   },
   "source": [
    "<h4> Load data and store in dataframe </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9nF2OKprnDTn",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the dataframe from a CSV file\n",
    "# We used the Housing dataset for this assignment which is attached for reference.\n",
    "df = pd.read_csv('../dataSetFull.csv')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nsdRMXMZnDTq"
   },
   "source": [
    "<h4>Find out  what type of variable you are dealing with. This will help you find the right visualization method for that variable.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Exploration Functions ###\n",
    "\n",
    "# Get the number of rows and columns in the data set\n",
    "def display_dataframe_shape(df):\n",
    "    rows, columns = df.shape\n",
    "    print(\"There are {} rows and {} columns in the data set\".format(rows, columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the data set variables\n",
    "\n",
    "# Display the first 5 rows of the dataframe\n",
    "display(df.head())\n",
    "\n",
    "# Display the last 5 rows of the dataframe\n",
    "display(df.tail())\n",
    "\n",
    "# Display the shape of the dataframe\n",
    "display_dataframe_shape(df)\n",
    "\n",
    "# Display the data types of each column\n",
    "display(df.dtypes)\n",
    "\n",
    "# Categorical Nominal: ['location','city','governorate','state']\n",
    "# Categorical Ordinal:\n",
    "# Quantitative Numeric: ['price_tnd','price_eur','pieces','room','bathroom','age','distance_to_capital', 'garage', 'garden', 'concierge', 'beach_view', 'mountain_view', 'pool', 'elevator', 'furnished', 'equipped_kitchen', 'central_heating', 'air_conditioning']\n",
    "# Quantitative Ratio: ['Area','latt','long']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hlS_gWSWnDTv"
   },
   "source": [
    "# Visualisation Questions - 2 X 5 = 10 Marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ratiPWMcnDTx"
   },
   "source": [
    "### Question 1\n",
    "<h4>Fill the missing value for the continous variables with Mean(average) for proper data visualization\n",
    "<br><br>\n",
    "    Preprocess height - convert data in  format xx'xx to xx.xx Remove \"nan\" with Mode and convert the column to numerical\n",
    "<br><br>    \n",
    "    Preprocess weight - convert data in  format xxlbs to xx Remove \"nan\" with Mode and convert the column to numerical\n",
    "<h4>Do Univariate anlaysis for outliers detection for height and weight\n",
    "<br><br>\n",
    "<h4>Write the python code in the below cell to create appropriate visual to perform the above task.\n",
    "<h4> Answer in markdown cells below the visual\n",
    "<br><br>\n",
    "<ol>\n",
    "    <li>Summarise your findings from the visual</li>\n",
    "    <li>The reason for selecting the chart type you did</li>\n",
    "    <li>Mention the pre-attentive attributes used.(atleast 2)</li>\n",
    "    <li>Mention the gestalt principles used.(atleast 2)</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Cleaning ###\n",
    "\n",
    "# Strip the leading and trailing whitespaces from the columns\n",
    "df = df.map(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "# Delete \"id\" columns as its unique for each row and does not provide any useful information\n",
    "# Lattitude and Longitude attributes are not useful for our analysis. We can use city, governorate and location columns instead.\n",
    "# Even ID and pieces columns are not useful for our analysis, hence we can drop it.\n",
    "df.drop(columns=['id', 'latt', 'long', 'pieces'], inplace=True)\n",
    "\n",
    "# For age, let us format & convert ranges to oridinal values. For example, '30-50' will be converted to 5\n",
    "print(\"\\nage:\")\n",
    "unique_values = df['age'].unique()\n",
    "print(\"Before conversion: \", unique_values)\n",
    "df['age'] = df['age'].replace('0', 0)\n",
    "df['age'] = df['age'].replace('1-5', 1)\n",
    "df['age'] = df['age'].replace('5-10', 2)\n",
    "df['age'] = df['age'].replace('10-20', 3)\n",
    "df['age'] = df['age'].replace('10,20', 3)\n",
    "df['age'] = df['age'].replace('20-30', 4)\n",
    "df['age'] = df['age'].replace('30-50', 5)\n",
    "df['age'] = df['age'].replace('50-70', 6)\n",
    "df['age'] = df['age'].replace('70-100', 7)\n",
    "df['age'] = df['age'].replace('Plus de 100', 8)\n",
    "unique_values = df['age'].unique()\n",
    "print(\"After conversion: \", unique_values)\n",
    "\n",
    "display_dataframe_shape(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Preprocessing ###\n",
    "\n",
    "# Drop duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Compare the price_tnd and price_eur columns to see if they are correlated. If they are, we can use one of them for our analysis\n",
    "display(df[['price_tnd', 'price_eur']].describe())\n",
    "display(df[['price_tnd', 'price_eur']].corr())\n",
    "\n",
    "# Drop the price_tnd column as it is highly correlated with price_eur\n",
    "df.drop(columns=['price_tnd'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "display(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling missing values: city column\n",
    "\n",
    "before_processing = df['city'].isna().sum()\n",
    "print(\"Initial number of missing values in city column: \", before_processing)\n",
    "\n",
    "# Fetch all the location in each city, to fill missing values of city column more meaningfully.\n",
    "city_location = {}\n",
    "for city in df['city'].unique():\n",
    "    if type(city) == str:\n",
    "        city_location[city] = df[df['city'] == city]['location'].unique().tolist()\n",
    "\n",
    "# Fill missing values in city column using location column\n",
    "for city in city_location.keys():\n",
    "    df.loc[(df['city'].isna()) & (df['location'].isin(city_location[city])), 'city'] = city\n",
    "\n",
    "nan_values = df['city'].isna().sum()\n",
    "filled_values = before_processing - nan_values\n",
    "\n",
    "print(\"Number of city records filled smartly: \", filled_values)\n",
    "print(\"Number of city records remaining which are still empty (will be removed): \", nan_values)\n",
    "\n",
    "# Remove city records if the location is not available\n",
    "df.dropna(subset=['city'], inplace=True)\n",
    "\n",
    "display_dataframe_shape(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling missing values: state, age, room, bathroom, distance_to_capital, Area, price_eur\n",
    "\n",
    "# Fill missing values of state using mode.\n",
    "df['state'].fillna(df['state'].mode()[0], inplace=True)\n",
    "\n",
    "# Fill missing values of age using median.\n",
    "df['age'].fillna(df['age'].median(), inplace=True)\n",
    "\n",
    "# Fill missing values in 'room' column with the median value\n",
    "df['room'].describe()\n",
    "df['room'].fillna(df['room'].median(), inplace=True)\n",
    "df['room'].describe()\n",
    "\n",
    "# Fill missing values in 'bathroom' column with the median value\n",
    "df['bathroom'].describe()\n",
    "df['bathroom'].fillna(df['bathroom'].median(), inplace=True)\n",
    "df['bathroom'].describe()\n",
    "\n",
    "# Fill missing values in 'distance_to_capital' column with the median frequent value\n",
    "df['distance_to_capital'].describe()\n",
    "df['distance_to_capital'].fillna(df['distance_to_capital'].median(), inplace=True)\n",
    "df['distance_to_capital'].describe()\n",
    "\n",
    "# Fill missing values in 'Area' column with the median value\n",
    "df['Area'].describe()\n",
    "df['Area'].fillna(df['Area'].median(), inplace=True)\n",
    "df['Area'].describe()\n",
    "\n",
    "# Fill missing values in 'price_eur' column with the median value\n",
    "df['price_eur'].describe()\n",
    "df['price_eur'].fillna(df['price_eur'].median(), inplace=True)\n",
    "df['price_eur'].describe()\n",
    "\n",
    "# Check for missing values\n",
    "display(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once we fill the missing values in the dataset, we can convert the columns to their appropriate data types.\n",
    "\n",
    "print(\"\\nBefore conversion:\")\n",
    "print(df.dtypes.value_counts())\n",
    "# TODO: CHECK BELOW CONVERSION IS REQUIRED AS WE USE MEDIAN INSTEAD OF MEAN.\n",
    "df = df.astype({'price_eur': 'int', 'room': 'int', 'bathroom': 'int', 'age': 'int', 'state': 'int'})\n",
    "print(\"\\nAfter conversion:\")\n",
    "print(df.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of records before final duplicates removal: \", df.shape[0])\n",
    "\n",
    "# Drop duplicates if any after filling missing values\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "print(\"Total number of records after final duplicates removal: \", df.shape[0])\n",
    "\n",
    "# Check for missing values after filling and converting\n",
    "display(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the pre-processed data in a new CSV file which can be used for tableau visualization\n",
    "df.to_csv('preprocessed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Outlier detection and removal\n",
    "# Check if csv file should be created after outlier removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Pending:\n",
    "# Do Univariate anlaysis for outliers detection for height and weight\n",
    "\n",
    "# Write the python code in the below cell to create appropriate visual to perform the above task.\n",
    "#  Answer in markdown cells below the visual\n",
    "#     Summarise your findings from the visual\n",
    "#     The reason for selecting the chart type you did\n",
    "#     Mention the pre-attentive attributes used.(atleast 2)\n",
    "#     Mention the gestalt principles used.(atleast 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "diRYcB0ZnDT9"
   },
   "source": [
    "### Question 2\n",
    "<h4>Do Bi-Variate anlaysis for outliers detection for height and weight \n",
    "<br><br>\n",
    "<h4>Write the python code in the below cell to create appropriate visual to perform the above task.\n",
    "<h4> Answer in markdown cells below the visual\n",
    "<br><br>\n",
    "<ol>\n",
    "    <li>Summarise your findings from the visual</li>\n",
    "    <li>The reason for selecting the chart type you did</li>\n",
    "    <li>Mention the pre-attentive attributes used.(atleast 2)</li>\n",
    "    <li>Mention the gestalt principles used.(atleast 2)</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rs2QzLvdnDT-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQkg7ciNnDT_"
   },
   "source": [
    "### Question 3\n",
    "<h4>What kind of co-relation exists between Age and Overall\n",
    "<br><br>    \n",
    "Write the python code in the below cell to create appropriate visual to perform the above task.\n",
    "<h4> Answer in markdown cells below the visual\n",
    "<br><br>\n",
    "<ol>\n",
    "    <li>Summarise your findings from the visual</li>\n",
    "    <li>The reason for selecting the chart type you did</li>\n",
    "    <li>Mention the pre-attentive attributes used.(atleast 2)</li>\n",
    "    <li>Mention the gestalt principles used.(atleast 2)</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nExKkhfZnDUB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DeuNFfRpnDUD"
   },
   "source": [
    "  ### Question 4\n",
    "<h4>What kind of relation exists between Age and (potential vs Overall). Create an appropriate visual to compare potential vs Overall with respect to age in one single visual.\n",
    "<br><br>\n",
    "Write the python code in the below cell to create appropriate visual to perform the above task.\n",
    "<h4> Answer in markdown cells below the visual\n",
    "<br><br>\n",
    "<ol>\n",
    "    <li>Summarise your findings from the visual</li>\n",
    "    <li>The reason for selecting the chart type you did</li>\n",
    "    <li>Mention the pre-attentive attributes used.(atleast 2)</li>\n",
    "    <li>Mention the gestalt principles used.(atleast 2)</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U2HspEG6nDUE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lF9Sdb7ynDUG"
   },
   "source": [
    "  ### Question 5\n",
    "<h4>What kind of relation exists between Player Vision and Player Value. Create an appropriate visual to show any kind of relation that exists between Vision and Value of the player in one single visual.\n",
    "<br><br>\n",
    "Write the python code in the below cell to create appropriate visual to perform the above task.\n",
    "<h4> Answer in markdown cells below the visual\n",
    "<br><br>\n",
    "<ol>\n",
    "    <li>Summarise your findings from the visual</li>\n",
    "    <li>The reason for selecting the chart type you did</li>\n",
    "    <li>Mention the pre-attentive attributes used.(atleast 2)</li>\n",
    "    <li>Mention the gestalt principles used.(atleast 2)</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ciXnXIuGoCKE"
   },
   "source": [
    "# Group's choice-2 Marks\n",
    " \n",
    "#### Frame 1 (more) question which will help in the EDA(Exploratory Data Analysis) of the given data set and answer the same using the best visual.\n",
    " \n",
    " 1. Write the question in a markdown cell\n",
    " 2. Below the question,in a coding cell,write the python code to create the visual to answer the question  \n",
    "\n",
    "<h4> Answer in markdown cells below the visual <br><br>\n",
    "   1.Summarise your findings from the visual.<br>\n",
    "   2.The reason for selecting the chart type you did <br>\n",
    "   3.Mention the pre-attentive attributes used.(atleast 2)<br>\n",
    "   4.Mention the gestalt principles used.(atleast 2)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RhzvYzb0nDUI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dy22QpOZnDUK"
   },
   "source": [
    "<h1><center> ************ END OF ASSIGNMENT ****************</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bzlvXa1dnDUL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "dvi-a2-ps1-wb.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
